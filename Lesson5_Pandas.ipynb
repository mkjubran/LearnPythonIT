{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson5 Pandas.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LIS0hP4MHLQq",
        "Nz6uowYjHLSI",
        "mblughKXHLSJ",
        "_G6tcOfcHLSK",
        "F2rxN9foHT2s",
        "AV0pvJC9HT3j",
        "SV6CCg2IHT4K",
        "gLbBW_4CHT4b",
        "EeTVJT8LHT4c",
        "qL2289ZSHT4g",
        "ghBHte7yHT49",
        "POTZggBHHT4-",
        "ficuB--7HT5D",
        "GQOWSGAbHT5F",
        "-w_lkna1HT5U",
        "hBXeYWbNHT5V",
        "ce9Otb9OHT5W",
        "zu5WshBYHT5h",
        "bSjXKVBQHT5j",
        "IKKHdGeYHT5m",
        "NKLPnx6cHT50",
        "7Fzg7R7AHT6X",
        "uFDQb79iHT6Y",
        "QlTxtiLdHT6Y",
        "xhn6n--AHT6a",
        "TOX3-hzSHT6a",
        "m-Sk6xoWHT6y",
        "0B29k_bgHT6-",
        "6fgijQ7LHT6_",
        "loV2GYoiHeQ1",
        "hqByq7gTHeTA",
        "3cGQJCsoHeTB",
        "Ky9ZNCQWHeT_",
        "nuDP5Z9THeUC",
        "IIxilHT29hXt",
        "KWQVHM5DHeVF",
        "hMUvH1jaHeVF",
        "dfUfefoqHeVN",
        "_bxLR_E8HeV9",
        "wpdrFiVnHeV-",
        "5ly5K57ZHT7A",
        "pSLyA8HsHeV-"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkjubran/LearnPythonIT/blob/main/Lesson5_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PP5OHO_HLPU"
      },
      "source": [
        "<!--NAVIGATION-->\n",
        "\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/smabb/p/blob/master/Lesson6 Pandas.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n",
        "\n",
        "|                                        -                                        |                                        -                                        |                                        -                                        |\n",
        "|---------------------------------------------------------------------------------|---------------------------------------------------------------------------------|---------------------------------------------------------------------------------|\n",
        "|          [Exercise 1 (read series)](<#Exercise-1-(read-series&#41;>)          | [Exercise 2 (operations on series)](<#Exercise-2-(operations-on-series&#41;>) |       [Exercise 3 (inverse series)](<#Exercise-3-(inverse-series&#41;>)    |\n",
        "|       [Exercise 4 (cities)](<#Exercise-4-(cities&#41;>)                    |          [Exercise 5 (powers of series)](<#Exercise-5-(powers-of-series&#41;>) |    [[Exercise 6 (municipalities)](<#Exercise-6-(municipalities-of-finland&#41;>)    |\n",
        "|       [Exercise 7 (swedish and foreigners)](<#Exercise-7-(swedish-and-foreigners&#41;>)    |    [Exercise 8 (growing municipalities)](<#Exercise-8-(growing-municipalities&#41;>)       |   [Exercise 9 (subsetting with loc)](<#Exercise-9-(subsetting-with-loc&#41;>)    |\n",
        "|       [Exercise 10 (subsetting by positions)](<#Exercise-`0-(subsetting-by-positions&#41;>)   |                [Exercise 11 (snow depth)](<#Exercise-11-(snow-depth&#41;>)                |\n",
        "|      [Exercise 12 (average temperature)](<#Exercise-10-(average-temperature&#41;>)      |               [Exercise 13 (below zero)](<#Exercise-13-(below-zero&#41;>)               |                 [Exercise 14 (cyclists)](<#Exercise-14-(cyclists&#41;>)                 |\n",
        "|      [Exercise 15 (missing value types)](<#Exercise-15-(missing-value-types&#41;>)      |   [Exercise 16 (special missing values)](<#Exercise-16-(special-missing-values&#41;>)   |                [Exercise 17 (last week)](<#Exercise-17-(last-week&#41;>)                |\n",
        "|               [Exercise 18 (split date)](<#Exercise-18-(split-date&#41;>)               | [Exercise 19 (split date continues)](<#Exercise-19-(split-date-continues&#41;>)                |\n",
        "|      [Exercise 20 (cycling weather)](<#Exercise-20-(cycling-weather&#41;>)     |  [Exercise 21 (cyclists per day)](<#Exercise-21-(cyclists-per-day&#41;>)     |  [Exercise 22 (best performer)](<#Exercise-22-(best-performer&#41;>)                |\n",
        "|      [Exercise 23 (bicycle timeseries)](<#Exercise-23-(bicycle-timeseries&#41;>)     |  [Exercise 24 (commute)](<#Exercise-24-(commute&#41;>)              |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltf9JhvRHLPa"
      },
      "source": [
        "# Pandas\n",
        "\n",
        "In the NumPy section we dealt with some arrays, whose columns had each a special meaning. For example, the column number 0 could contain values interpreted as years, and column 1 could contain a month, and so on. It is possible to handle the data this way, but in can be hard to remember, which column number corresponds to which variable. Especially, if you later remove some column from the array, then the numbering of the remaining columns changes. One solution to this is to give a descriptive name to each column. These column names stay fixed and attached to their corresponding columns, even if we remove some of the columns. In addition, the rows can be given names as well, these are called *indices* in Pandas.\n",
        "\n",
        "The [Pandas](http://pandas.pydata.org/) library is built on top of the NumPy library, and it provides a special kind of two dimensional data structure called `DataFrame`. The `DataFrame` allows to give names to the columns, so that one can access a column using its name in place of the index of the column.\n",
        "\n",
        "First we will quickly go through a few examples to see what is possible with Pandas. You may need to check some details from the Pandas [documentation](http://pandas.pydata.org/pandas-docs/stable/) in order to complete the exercises. We start by doing some standard imports:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf28kbnoHLPd"
      },
      "source": [
        "import pandas as pd    # This is the standard way of importing the Pandas library\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgYK8elOHLPr"
      },
      "source": [
        "Let's import some weather data that is in text form in a csv (Commma Separated Values) file. The following call will fetch the data from the internet and convert it to a DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZaRAtcBHLPw"
      },
      "source": [
        "wh = pd.read_csv(\"https://raw.githubusercontent.com/smabb/p/master/data/temp.csv\")\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxNt4GAoHLP7"
      },
      "source": [
        "We see that the DataFrame contains eight columns, three of which are actual measured variables. Now we can refer to a column by its name:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCfDXBG4HLP9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAF2t-vCHLQE"
      },
      "source": [
        "There are several summary statistic methods that operate on a column or on all the columns. The next example computes the mean of the temperatures over all rows of the DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QdxCZLNHLQG"
      },
      "source": [
        "  # Mean temperature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICIumzUyHLQN"
      },
      "source": [
        "We can drop some columns from the DataFrame with the `drop` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz7ds36LHLQO"
      },
      "source": [
        " # Return a copy with one column removed, the original DataFrame stays intact"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C6h4D04HLQU"
      },
      "source": [
        "wh.head()     # Original DataFrame is unchanged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DnhFAu2HLQb"
      },
      "source": [
        "In case you want to modify the original DataFrame, you can either assign the result to the original DataFrame, or use the `inplace` parameter of the `drop` method. Many of the modifying methods of the DataFrame have the `inplace` parameter.\n",
        "\n",
        "Addition of a new column works like adding a new key-value pair to a dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnc1yie4HLQf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEpK2KDuHLQn"
      },
      "source": [
        "In the next sections we will systematically go through the DataFrame and its one-dimensional version: *Series*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIS0hP4MHLQq"
      },
      "source": [
        "## Creation and indexing of series\n",
        "\n",
        "One can turn any one-dimensional iterable into a Series, which is a one-dimensional data structure:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-qWhxcZHLQs"
      },
      "source": [
        "s=pd.Series([1, 4, 5, 2, 5, 2])\n",
        "s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPlkHn7iHLQx"
      },
      "source": [
        "The data type of the elements in this Series is `int64`, integers representable in 64 bits. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQH336BgHLQ0"
      },
      "source": [
        "We can also attach a name to this series:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23-Oyym-HLQ1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evk3yYuJHLQ6"
      },
      "source": [
        "The common attributes of the series are the `name`, `dtype`, and `size`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXNOkHGUHLQ7"
      },
      "source": [
        "print(f\"Name: {s.name}, dtype: {s.dtype}, size: {s.size}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dmUaRnYHLQ_"
      },
      "source": [
        "In addition to the values of the series, also the row indices were printed. All the accessing methods from NumPy arrays also work for the Series: indexing, slicing, masking and fancy indexing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u3C091FHLRB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtSmlBycHLRG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7UjezGfHLRK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzcWulVZHLRP"
      },
      "source": [
        "Note that the indices stick to the corresponding values, they are not renumbered!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCZDJN8dHLRR"
      },
      "source": [
        "                     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoOBBpP0HLRV"
      },
      "source": [
        "The values as a NumPy array are accessible via the `values` attribute:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF2RdOQnHLRX"
      },
      "source": [
        "s2.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0lYsvy4HLRa"
      },
      "source": [
        "And the indices are available through the `index` attribute:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4yp4WznHLRc"
      },
      "source": [
        "s2.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_jy59V_HLRh"
      },
      "source": [
        "The index is not simply a NumPy array, but a data structure that allows fast access to the elements. The indices need not be integers, as the next example shows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ9YJ4NoHLRi"
      },
      "source": [
        "s3=pd.Series([1, 4, 5, 2, 5, 2], index=list(\"abcdef\"))\n",
        "s3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-dSmgpgHLRt"
      },
      "source": [
        "s3.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQRnr7hmHLRx"
      },
      "source": [
        "s3[\"b\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVN9XmFYHLR0"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "Note a special case here: if the indices are not integers, then the last index of the slice is included in the result. This is contrary to slicing with integers!\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQdPfamyHLR0"
      },
      "source": [
        "s3[\"b\":\"e\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9KnEmtDHLR4"
      },
      "source": [
        "It is still possible to access the series using NumPy style *implicit integer indices*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w62YA53mHLR4"
      },
      "source": [
        "s3[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oedsBt2QHLR8"
      },
      "source": [
        "This can be confusing though. Consider the following series:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrWu4MpRHLR9"
      },
      "source": [
        "s4 = pd.Series([\"Jack\", \"Jones\", \"James\"], index=[1,2,3])\n",
        "s4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox65aS6XHLSD"
      },
      "source": [
        "What do you think `s4[1]` will print? For this ambiguity Pandas offers attributes `loc` and `iloc`. The attributes `loc` always uses the explicit index, while the attribute `iloc` always uses the implicit integer index:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylKqkiW8HLSG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz6uowYjHLSI"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 1 (read series)</div>\n",
        "\n",
        "Write function `read_series` that reads input lines from the user and return a Series. Each line should contain first the index and then the corresponding value, separated by whitespace. The index and values are strings (in this case `dtype` is `object`). An empty line signals the end of Series. Malformed input should cause an exception. An input line is malformed, if it is empty and, when split at whitespace, does not result in two parts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "515wO1nuJusQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mblughKXHLSJ"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 2 (operations on series)</div>\n",
        "\n",
        "Write function `create_series` that gets two lists of numbers as parameters. Both lists should have length 3.\n",
        "The function should first create two Series, `s1` and `s2`. The first series should have values from the first parameter list and have corresponding indices `a`, `b`, and  `c`. The second series should get its values from the second parameter list and have again the corresponding indices `a`, `b`, and  `c`. The function should return the pair of these Series.\n",
        "\n",
        "Then, write a function `modify_series` that gets two Series as parameters. It should add to the first Series `s1` a new value with index `d`. The new value should be the same as the value in Series `s2` with index `b`.\n",
        "Then delete the element from `s2` that has index `b`. Now the first Series should have four values, while the second list has only two values. Adding a new element to a Series can be achieved by assignment, like with dictionaries. Deletion of an element from a Series can be done with the `del` statement.\n",
        "\n",
        "Try adding together the Series returned by the `modify_series` function. The operations on Series use the indices to keep the element-wise operations *aligned*. If for some index the operation could not be performed, the resulting value will be `NaN` (Not A Number).\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5j5ch_AJvKz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G6tcOfcHLSK"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 3 (inverse series)</div>\n",
        "\n",
        "Write function `inverse_series` that get a Series as a parameter and returns a new series, whose indices and values have swapped roles. \n",
        "\n",
        "What happens if some value appears multiple times in the original Series? What happens if you use this value to index the resulting Series?\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DoEDc5LJz8F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9jL1XR2HLSL"
      },
      "source": [
        "One may notice that there are similarities between Python's dictionaries and Pandas' Series, both can be thought to access values using keys. \n",
        "\n",
        "As a mark of the similaries between these two data structures, Pandas allows creation of a `Series` object from a dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM_8ggHlHLSL"
      },
      "source": [
        "d = { 2001 : \"Bush\", 2005: \"Bush\", 2009: \"Obama\", 2013: \"Obama\", 2017 : \"Trump\"}\n",
        "s4 = pd.Series(d)\n",
        "s4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6neiHi8iHT2W"
      },
      "source": [
        "# Pandas (continues)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxt5hgFuHT2a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2rxN9foHT2s"
      },
      "source": [
        "## Creation of dataframes\n",
        "\n",
        "The DataFrame is essentially a two dimensional object, and it can be created in three different ways:\n",
        "\n",
        "* out of a two dimensional NumPy array\n",
        "* out of given columns\n",
        "* out of given rows\n",
        "\n",
        "### Creating DataFrames from a NumPy array\n",
        "\n",
        "In the following example a DataFrame with 2 rows and 3 column is created. The row and column indices are given explicitly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pwxWwPXHT2x"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbYs7UtqHT3C"
      },
      "source": [
        "Note that now both the rows and columns can be accessed using the special `Index` object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_O9BefTHT3E"
      },
      "source": [
        "df.index                            # These are the \"row names\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ROLLXVnHT3M"
      },
      "source": [
        "df.columns                          # These are the \"column names\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rey9MOjXHT3T"
      },
      "source": [
        "If either `columns` or `index` argument is left out, then an implicit integer index will be used:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHXvY8_dHT3V"
      },
      "source": [
        "df2=pd.DataFrame(np.random.randn(2,3), index=[\"a\", \"b\"])\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6k5EJmWHT3a"
      },
      "source": [
        "Now the column index is an object similar to Python's builtin `range` type:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAXmf2LkHT3c"
      },
      "source": [
        "df2.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV0pvJC9HT3j"
      },
      "source": [
        "### Creating DataFrames from columns\n",
        "\n",
        "A column can be specified as a list, an NumPy array, or a Pandas' Series. The names of the columns can be given either with the `columns` parameter, or if Series objects are used, then the `name` attribute of each Series is used as the column name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHzA_eBNHT3l"
      },
      "source": [
        "s1 = pd.Series([1,2,3])\n",
        "s1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfPw5czqHT3q"
      },
      "source": [
        "s2 = pd.Series([4,5,6], name=\"b\")\n",
        "s2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLK8CtwVHT3y"
      },
      "source": [
        "Give the column name explicitly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rSEcqKAHT31"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_k9-u2jHT36"
      },
      "source": [
        "Use the `name` attribute of Series s2 as the column name:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec8YCfgeHT38"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE76K6zaHT3_"
      },
      "source": [
        "If using multiple columns, then they must be given as the dictionary, whose keys give the column names and values are the actual column content."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuHS5CX5HT4B"
      },
      "source": [
        "pd.DataFrame({\"a\": s1, \"b\": s2})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV6CCg2IHT4K"
      },
      "source": [
        "### Creating DataFrames from rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_g66EpEHT4L"
      },
      "source": [
        "We can give a list of rows as a parameter to the DataFrame constructor. Each row is given as a dict, list, Series, or NumPy array. If we want to give names for the columns, then either the rows must be dictionaries, where the key is the column name and the values are the elements of the DataFrame on that row and column, or else the column names must be given explicitly. An example of this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP-X3bqBHT4N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3Ju2COhHT4S"
      },
      "source": [
        "Or:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSI76Vb4HT4S"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLbBW_4CHT4b"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 4 (cities)</div>\n",
        "\n",
        "Write function `cities` that returns the following DataFrame of top  cities by population:\n",
        "\n",
        "```\n",
        "                 Population Total area\n",
        "Helsinki         643272     715.48\n",
        "Espoo            279044     528.03\n",
        "Tampere          231853     689.59\n",
        "Vantaa           223027     240.35\n",
        "Oulu             201810     3817.52\n",
        "```\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJeY8yHXMijG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeTVJT8LHT4c"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 5 (powers of series)</div>\n",
        "\n",
        "Make function `powers_of_series` that takes a Series and a positive integer `k` as parameters and returns a DataFrame. The resulting DataFrame should have the same index as the input Series. The first column of the dataFrame should be the input Series, the second column should contain the Series raised to power of two. The third column should contain the Series raised to the power of three, and so on until (and including) power of `k`. The columns should have indices from 1 to k.\n",
        "\n",
        "The values should be numbers, but the index can have any type.\n",
        ". Example of usage:\n",
        "\n",
        "```\n",
        "s = pd.Series([1,2,3,4], index=list(\"abcd\"))\n",
        "print(powers_of_series(s, 3))\n",
        "```\n",
        "Should print:\n",
        "```\n",
        "   1   2   3\n",
        "a  1   1   1\n",
        "b  2   4   8\n",
        "c  3   9  27\n",
        "d  4  16  64\n",
        "```\n",
        "\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NWGgNdq68xS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL2289ZSHT4g"
      },
      "source": [
        "## Accessing columns and rows of a dataframe\n",
        "\n",
        "Even though DataFrames are basically just two dimensional arrays, the way to access their elements is different from NumPy arrays. There are a couple of complications, which we will go through in this section.\n",
        "\n",
        "Firstly, the bracket notation `[]` does not allow the use of an index pair to access a single element of the DataFrame. Instead only one dimension can be specified.\n",
        "\n",
        "Well, does this dimension specify the rows of the DataFrame, like NumPy arrays if only one index is given, or does it specify the columns of the DataFrame?\n",
        "\n",
        "It depends!\n",
        "\n",
        "If an integer is used, then it specifies a column of the DataFrame in the case the **explicit** indices for the column contain that integer. In any other case an error will result. For example, with the above DataFrame, the following indexing will not work, because the explicit column index consist of the column names \"Name\" and \"Wage\" which are not integers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gq69rH6HT4h"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zZuGe4_HT4l"
      },
      "source": [
        "The following will however work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMUrZnATHT4n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlBmicmcHT4s"
      },
      "source": [
        "As does the fancy indexing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcVZJH2sHT4t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWFqBQYtHT4x"
      },
      "source": [
        "If one indexes with a slice or a boolean mask, then the **rows** are referred to. Examples of these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2oju8_XHT4y"
      },
      "source": [
        "                          # slice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4uyATteHT42"
      },
      "source": [
        "            # boolean mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yD7ZLtpHT45"
      },
      "source": [
        "If some of the above calls return a Series object, then you can chain the bracket calls to get a single value from the DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gMlnfcbHT45"
      },
      "source": [
        "               # Note order of dimensions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b03D1rZHT49"
      },
      "source": [
        "But there is a better way to achieve this, which we will see in the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghBHte7yHT49"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 6 (municipalities )</div>\n",
        "\n",
        "Load the municipal information DataFrame(https://raw.githubusercontent.com/smabb/p/master/data/muni.csv), Use the function pd.read_csv. The rows of the DataFrame correspond to various geographical areas of Finland. The first row is about Finland as a whole, then rows from Akaa to Äänekoski are municipalities of Finland in alphabetical order. After that some larger regions are listed.\n",
        "\n",
        "Write function `municipalities` that returns a DataFrame containing only rows about municipalities.\n",
        "Give an appropriate argument for `pd.read_csv` so that it interprets the column about region name as the (row) index. This way you can index the DataFrame with the names of the regions.\n",
        "\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yTafWUdQwEK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POTZggBHHT4-"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 7 (swedish and foreigners)</div>\n",
        "\n",
        "Write function `swedish_and_foreigners` that\n",
        "\n",
        "* Reads the municipalities data set\n",
        "* Takes the subset about municipalities (like in previous exercise)\n",
        "* Further take a subset of rows that have proportion of Swedish speaking people and proportion of foreigners both above 5 % level\n",
        "* From this data set take only columns about population, the proportions of Swedish speaking people and foreigners, that is three columns.\n",
        "\n",
        "The function should return this final DataFrame.\n",
        "\n",
        "Do you see some kind of correlation between the columns about Swedish speaking and foreign people? Do you see correlation between the columns about the population and the proportion of Swedish speaking people in this subset?\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nj0GrMIQwcg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ficuB--7HT5D"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 8 (growing municipalities)</div>\n",
        "\n",
        "Write function `growing_municipalities` that gets subset of municipalities (a DataFrame) as a parameter and returns the proportion of municipalities with increasing population in that subset.\n",
        "\n",
        "\n",
        "Print the proportion as percentages using 1 decimal precision.\n",
        "\n",
        "Example output:\n",
        "\n",
        "```\n",
        "Proportion of growing municipalities: 12.4%\n",
        "```\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftUXtTbVQ-Vt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQOWSGAbHT5F"
      },
      "source": [
        "## Alternative indexing and data selection\n",
        "\n",
        "If the explanation in the previous section sounded confusing or ambiguous, or if you didn't understand a thing, you don't have to worry.\n",
        "\n",
        "There is another way to index Pandas DataFrames, which\n",
        "\n",
        "* allows use of index pairs to access a single element\n",
        "* has the same order of dimensions as NumPy: first index specifies rows, second columns\n",
        "* is not ambiguous about implicit or explicit indices\n",
        "\n",
        "Pandas DataFrames have attributes `loc` and `iloc` that have the above qualities.\n",
        "You can use `loc` and `iloc` attributes and forget everything about the previous section. Or you can use these attributes\n",
        "and sometimes use the methods from the previous section as shortcuts if you understand them well.\n",
        "\n",
        "The difference between `loc` and `iloc` attributes is that the former uses explicit indices and the latter uses the implicit integer indices. Examples of use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGoSD0NNHT5I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G56OjgWrHT5M"
      },
      "source": [
        "           # Right lower corner of the DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTj8WbRpHT5Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSciu6p1HT5T"
      },
      "source": [
        "With `iloc` everything works like with NumPy arrays: indexing, slicing, fancy indexing, masking and their combinations. With `loc` it is the same but now the names in the explicit indices are used for specifying rows and columns. Make sure your understand why the above examples work as they do!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w_lkna1HT5U"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 9 (subsetting with loc)</div>\n",
        "\n",
        "Write function `subsetting_with_loc` that in one go takes the subset of municipalities from Akaa to Äänekoski and restricts it to columns: \"Population\", \"Share of Swedish-speakers of the population, %\", and \"Share of foreign citizens of the population, %\".\n",
        "The function should return this content as a DataFrame. Use the attribute `loc`.\n",
        "\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlvHr9eWLpkX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBXeYWbNHT5V"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 10 (subsetting by positions)</div>\n",
        "\n",
        "Write function `subsetting_by_positions` that return the 1st 10 elements by index positons from the previous excercise.\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPoOEiznSXaL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce9Otb9OHT5W"
      },
      "source": [
        "## Summary statistics\n",
        "\n",
        "The summary statistic methods work in a similar way as their counter parts in NumPy. By default, the aggregation is done over columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jvx0OF9HT5X"
      },
      "source": [
        "wh = pd.read_csv(\"https://raw.githubusercontent.com/smabb/p/master/data/temp.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOFMUYlFHT5a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stG8bu4wHT5d"
      },
      "source": [
        "The `describe` method of the `DataFrame` object gives different summary statistics for each (numeric) column. The result is a DataFrame. This method gives a good overview of the data, and is typically used in the exploratory data analysis phase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUDa7za6HT5d"
      },
      "source": [
        "wh.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu5WshBYHT5h"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 11 (snow depth)</div>\n",
        "\n",
        "Write function `snow_depth` that reads in the weather Dataset https://raw.githubusercontent.com/smabb/p/master/data/temp.csv  and returns the maximum amount of snow in the year 2017.\n",
        "\n",
        "Print the result in the following form\n",
        "```\n",
        "Max snow depth: xx.x\n",
        "```\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlPHdXeoSzLV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSjXKVBQHT5j"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 12 (average temperature)</div>\n",
        "\n",
        "Write function `average_temperature` that returns the average temperature in July.\n",
        "\n",
        "Print the result in following form:\n",
        "```\n",
        "Average temperature in July: xx.x\n",
        "```\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2D9RCT45wUr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKKHdGeYHT5m"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 13 (below zero)</div>\n",
        "\n",
        "Write function `below_zero` that returns the number of days when the temperature was below zero.\n",
        "\n",
        "Print the result inin the following form:\n",
        "\n",
        "```\n",
        "Number of days below zero: xx\n",
        "```\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev_p5LMh5wxd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKLPnx6cHT50"
      },
      "source": [
        "## Missing data\n",
        "\n",
        "You may have noticed something strange in the output of the `describe` method. First, the minimum value in both precipitation and snow depth fields is -1. The special value -1 means that on that day there was absolutely no snow or rain, whereas the value 0 might indicate that the value was close to zero. Secondly, the snow depth column has count 358, whereas the other columns have count 365, one measurement/value for each day of the year. How is this possible? Every field in a DataFrame should have the same number of rows. Let's use the `unique` method of the Series object to find out, which different values are used in this column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NflnOdg6HT51"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-By6rHCHT52"
      },
      "source": [
        "The `float` type allows a special value `nan` (Not A Number), in addition to normal floating point numbers. This value can represent the result from an illegal operation. For example, the operation 0/0 can either cause an exception to occur or just silently produce a `nan`. In Pandas `nan` can be used to represent a missing value. In the weather DataFrame the `nan` value tells us that the measurement from that day is not available, possibly due to a broken measuring instrument or some other problem.\n",
        "\n",
        "Note that only float types allow the `nan` value (in Python, NumPy or Pandas). So, if we try to create an integer series with missing values, its dtype gets promoted to `float`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSUTugvPHT53"
      },
      "source": [
        "pd.Series([1,3,2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf-GHd0kHT55"
      },
      "source": [
        "pd.Series([1,3,2, np.nan])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao5V4FrHHT58"
      },
      "source": [
        "For non-numeric types the special value `None` is used to denote a missing value, and the dtype is promoted to `object`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-flsOh-jHT58"
      },
      "source": [
        "pd.Series([\"jack\", \"joe\", None])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCh7K2FXHT6A"
      },
      "source": [
        "Pandas excludes the missing values from the summary statistics, like we saw in the previous section. Pandas also provides some functions to handle missing values.\n",
        "\n",
        "The missing values can be located with the `isnull` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyC23g77HT6B"
      },
      "source": [
        "     # returns a boolean mask DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhLd_dPBHT6E"
      },
      "source": [
        "This is not very useful as we cannot directly use the mask to index the DataFrame. We can, however, combine it with the `any` method to find out all the rows that contain at least one missing value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzfeUQIjHT6G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsgMcC62HT6K"
      },
      "source": [
        "The `notnull` method works conversively to the `isnull` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPus9l0jHT6K"
      },
      "source": [
        "The `dropna` method of a DataFrame drops columns or rows that contain missing values from the DataFrame, depending on the `axis` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lGdmoJL7LnB"
      },
      "source": [
        "wh = pd.read_csv(\"https://raw.githubusercontent.com/smabb/p/master/data/temp.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwCHkkwD66Bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066eeca8-1cf7-46a9-90d1-161b0a2309b8"
      },
      "source": [
        "wh.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(365, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUcYKNCSHT6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d4af63e-9623-495d-ddce-11179d997bdf"
      },
      "source": [
        " wh.dropna().shape# Default axis is 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(365, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tcPpdhXHT6R"
      },
      "source": [
        " # Drops the columns containing missing values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S12ngYQhHT6T"
      },
      "source": [
        "The `how` and `thresh` parameters of the `dropna` method allow one to specify how many values need to be missing in order for the row/column to be dropped.\n",
        "\n",
        "The `fillna` method allows to fill the missing values with some constant or interpolated values. The `method` parameter can be:\n",
        "\n",
        "* `None`: use the given positional parameter as the constant to fill missing values with\n",
        "* `ffill`: use the previous value to fill the current value\n",
        "* `bfill`: use the next value to fill the current value\n",
        "\n",
        "For example, for the weather data we could use forward fill"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AroImDeRHT6U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fzg7R7AHT6X"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 14 (cyclists)</div>\n",
        "\n",
        "Write function `cyclists` that does the following.\n",
        "\n",
        "Load the Helsinki bicycle data set https://raw.githubusercontent.com/smabb/p/master/data/Helsinki_bicycle.csv . The dataset contains the number of cyclists passing by measuring points per hour. The data is gathered over about four years, and there are 20 measuring points around Helsinki. The dataset contains some empty rows at the end. Get rid of these. Also, get rid of columns that contain only missing values. Return the cleaned dataset. \n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0k8LQzbXIA0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFDQb79iHT6Y"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 15 (missing value types)</div>\n",
        "\n",
        "Make function `missing_value_types` that returns the following DataFrame. Use the `State` column as the (row) index. The value types for the two other columns should be `float` and `object`, respectively. Replace the dashes with the appropriate missing value symbols.\n",
        "\n",
        "State | Year of independence | President\n",
        "------|----------------------|----------\n",
        "United Kingdom | - | -\n",
        "Finland | 1917 | Niinistö\n",
        "USA | 1776 | Trump\n",
        "Sweden | 1523 | -\n",
        "Germany | - | Steinmeier\n",
        "Russia | 1992 | Putin\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I0mQZM6XgH7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlTxtiLdHT6Y"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 16 (special missing values)</div>\n",
        "\n",
        "Write function `special_missing_values` that does the following.\n",
        "\n",
        "Read the data set of the top hundred singles from the beginning of the year 1964 from(https://query.data.world/s/v2sc7li3mrhsivknqsjjt5w667aog5). Return the rows whose singles' position dropped compared to last week's position .\n",
        "\n",
        "\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOO2IFeZYsU7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhn6n--AHT6a"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 17 (last week)</div>\n",
        "\n",
        "\n",
        "\n",
        "Write function `last_week` that reads the top100 data set mentioned in the above exercise. The function should then try to reconstruct the top100 list of the previous week based on that week's list. Try to do this as well as possible. You can fill the values that are impossible to reconstruct by missing value symbols. Your solution should work for a top100 list of any week. So don't rely on specific features of this top100 list. \n",
        "\n",
        "Hint. First create the last week's top100 list of those songs that are also on this week's list. Then add those entries that were not on this week's list. Finally sort by position.\n",
        "\n",
        "Hint 2. The `where` method of Series and DataFrame can be useful. It can also be nested.  Read about the where method (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.where.html?highlight=where#pandas.DataFrame.where)\n",
        "\n",
        "Hint 3. Like in NumPy, you can use with Pandas the bitwise operators `&`, `|`, and `~`.\n",
        "Remember that he bitwise operators have higher precedence than the comparison operations, so you may\n",
        "have to use parentheses around comparisons, if you combined result of comparisons with bitwise operators.\n",
        "\n",
        "\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dNQFOHqX38b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOX3-hzSHT6a"
      },
      "source": [
        "## Converting columns from one type to another\n",
        "\n",
        "There are several ways of converting a column to another type. For converting single columns (a Series) one can use the `pd.to_numeric` function or the `map` method. For converting several columns in one go one can use the `astype` method. We will give a few examples of use of these methods/functions. For more details, look from the Pandas documentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc7bXYS8HT6b"
      },
      "source": [
        "pd.Series([\"1\",\"2\"]).map(int)                           # str -> int"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVpRzO9rHT6e"
      },
      "source": [
        "pd.Series([1,2]).map(str)                               # int -> str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVo3s9crHT6f"
      },
      "source": [
        "pd.to_numeric(pd.Series([1,1.0]), downcast=\"integer\")   # object -> int"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1DHmL_8HT6i"
      },
      "source": [
        "pd.to_numeric(pd.Series([1,\"a\"]), errors=\"coerce\")      # conversion error produces Nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk18bqD5HT6j"
      },
      "source": [
        "pd.Series([1,2]).astype(str)                            # works for a single series"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oiNCJmeHT6m"
      },
      "source": [
        "df = pd.DataFrame({\"a\": [1,2,3], \"b\" : [4,5,6], \"c\" : [7,8,9]})\n",
        "print(df.dtypes)\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQy7_Ab0HT6q"
      },
      "source": [
        "df.astype(float)                       # Convert all columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTPRL9XqHT6w"
      },
      "source": [
        "df2 = df.astype({\"b\" : float, \"c\" : str})    # different types for columns\n",
        "print(df2.dtypes)\n",
        "print(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-Sk6xoWHT6y"
      },
      "source": [
        "## String processing\n",
        "\n",
        "If the elements in a column are strings, then the vectorized versions of Python's string processing methods are available. These are accessed through the `str` attribute of a Series or a DataFrame. For example, to capitalize all the strings of a Series, we can use the `str.capitalize` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHEKK24WHT6z"
      },
      "source": [
        "names = pd.Series([\"donald\", \"theresa\", \"angela\", \"vladimir\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN8RP9TEHT61"
      },
      "source": [
        "One can find all the available methods by pressing the ctrl+space keys after the text `names.str.` in a Python prompt. Try it in below cell!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRkN6zA7HT62"
      },
      "source": [
        "names.str.  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJcehdh2HT64"
      },
      "source": [
        "We can split a column or Series into several columns using the `split` method. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLTnh5wyHT64"
      },
      "source": [
        "full_names = pd.Series([\"Donald Trump\", \"Theresa May\", \"Angela Merkel\", \"Vladimir Putin\"])\n",
        "full_names.str.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsZ9FVOVHT66"
      },
      "source": [
        "This is not exactly what we wanted: now each element is a list. We need to use the `expand` parameter to split into columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyfP8mGUHT66"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B29k_bgHT6-"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 18 (split date)</div>\n",
        "\n",
        "Read again the bicycle data set \n",
        "and clean it as in the earlier exercise. Then split the `Date` column into a DataFrame with five columns with column names `Weekday`, `Day`, `Month`, `Year`, and `Hour`. Note that you also need to to do some conversions. To get Hours, drop the colon and minutes. Convert field `Weekday` according the following rule:\n",
        "```\n",
        "ma -> Mon\n",
        "ti -> Tue\n",
        "ke -> Wed\n",
        "to -> Thu\n",
        "pe -> Fri\n",
        "la -> Sat\n",
        "su -> Sun\n",
        "```\n",
        "Convert the `Month` column according to the following mapping\n",
        "```\n",
        "tammi 1\n",
        "helmi 2\n",
        "maalis 3\n",
        "huhti 4\n",
        "touko 5\n",
        "kesä 6\n",
        "heinä 7\n",
        "elo 8\n",
        "syys 9\n",
        "loka 10\n",
        "marras 11\n",
        "joulu 12\n",
        "```\n",
        "\n",
        "Create function `split_date` that does the above and returns a DataFrame with five columns. You may want to use the `map` method of Series objects.\n",
        "\n",
        "So the first element in the `Date` column of the original data set should be converted from\n",
        "`ke 1 tammi 2014 00:00`\n",
        "to\n",
        "`Wed 1 1 2014 0` . \n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz4No2vsZ_bP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fgijQ7LHT6_"
      },
      "source": [
        "## Additional information\n",
        "\n",
        "We covered subsetting of DataFrames with the indexers `[]`, `.loc[]`, and `.iloc[]` quite concisely.\n",
        "For a more verbose explanation, look at the [tutorials at Dunder Data](https://medium.com/dunder-data/pandas-tutorials/home). Especially, the problems with chained indexing operators (like `df[\"a\"][1]`) are explained well there (tutorial 4), which we did not cover at all. As a rule of thumb: one should avoid chained indexing combined with assignment! See [Pandas documentation](http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#why-does-assignment-fail-when-using-chained-indexing)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRWZUValHeQg"
      },
      "source": [
        "# Pandas (continues)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWO7K45eHeQk"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loV2GYoiHeQ1"
      },
      "source": [
        "## Catenating datasets\n",
        "\n",
        "We already saw in the NumPy section how we can catenate arrays along an axis: `axis=0` catenates vertically and `axis=1` catenates horizontally, and so on. With the DataFrames of Pandas it works similarly except that the row indices and the column names require extra attention. Also note a slight difference in the name: `np.concatenate` but `pd.concat`.\n",
        "\n",
        "Let's start by considering catenation along the axis 0, that is, vertical catenation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHckZ3bFHeQ6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "826e7bef-b1c6-4322-8936-f356d90ab479"
      },
      "source": [
        "a=pd.DataFrame([['A0','B0'],['A1','B1']],columns=['A','B'])\n",
        "b=pd.DataFrame([['A2','B2'],['A3','B3']],columns=['A','B'],index=[2,3])\n",
        "c=pd.DataFrame([['C0','D0'],['C1','D1']],columns=['C','D'])\n",
        "d=pd.DataFrame([['B2','C2'],['B3','C3']],columns=['B','C'],index=[2,3])\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A0</td>\n",
              "      <td>B0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A1</td>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    A   B\n",
              "0  A0  B0\n",
              "1  A1  B1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm0K8sXRs_SY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "ce4f9de6-3b55-466b-b330-8733e7a21e82"
      },
      "source": [
        "b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A2</td>\n",
              "      <td>B2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A3</td>\n",
              "      <td>B3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    A   B\n",
              "2  A2  B2\n",
              "3  A3  B3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUSeuPf6s_bX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "16011f3e-5642-419d-a459-11e6eae56272"
      },
      "source": [
        "c"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C0</td>\n",
              "      <td>D0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C1</td>\n",
              "      <td>D1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    C   D\n",
              "0  C0  D0\n",
              "1  C1  D1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQDMW_BEs_iu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "0c86c69f-bca2-4fd0-d294-5ecc16cced58"
      },
      "source": [
        "d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B2</td>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B3</td>\n",
              "      <td>C3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    B   C\n",
              "2  B2  C2\n",
              "3  B3  C3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHKaxXFIHeRt"
      },
      "source": [
        "In the following simple case, the `concat` function works exactly as we expect it would:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_3THIRTHeRw"
      },
      "source": [
        "  # The default axis is 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INgjqFvSHeR8"
      },
      "source": [
        "The next, however, will create duplicate indices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8lEPCHPHeSA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEu4_qDNHeSI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm0lTGSvHeSO"
      },
      "source": [
        "This is not usually what we want! There are three solutions to this. Firstly, deny creation of duplicated indices by giving the `verify_integrity` parameter to the `concat` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxzqcmIHHeSQ"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4QiZ5E_HeSY"
      },
      "source": [
        "Secondly, we can ask for automatic renumbering of rows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyIaoXxLHeSc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nVuh2JaHeSk"
      },
      "source": [
        "Thirdly, we can ask for *hierarchical indexing*. The indices can contain multiple levels, but on this course we don't consider hierarchical indices in detail. Hierarchical indices can make a two dimensional array to work like higher dimensional array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ds-5xPxHeSm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCb4zSbpHeSq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRGhiaNEHeSu"
      },
      "source": [
        "Everything works similarly, when we want to catenate horizontally:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvq_jbBAHeSv"
      },
      "source": [
        "pd.concat([a,c], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akqmcTcmHeS1"
      },
      "source": [
        "We have so far assumed that when concatenating vertically the columns of both DataFrames are the same, and when joining horizontally the indices are the same. This is, however, not required:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UNt1EwZHeS2"
      },
      "source": [
        "pd.concat([a,d])   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv0fXCeZHeS7"
      },
      "source": [
        "It expanded the non-existing cases with `NaN`s. This method is called an *outer join*, which forms the union of columns in the two DataFrames. The alternative is *inner join*, which forms the intersection of columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMJWncDYHeS7"
      },
      "source": [
        "pd.concat([a,d], join=\"inner\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqByq7gTHeTA"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 19 (split date continues)</div>\n",
        "\n",
        "Write function `split_date_continues` that does\n",
        "\n",
        "* read the bicycle data set\n",
        "* clean the data set of columns/rows that contain only missing values\n",
        "* drops the `Date` column and replaces it with its splitted components as before\n",
        "\n",
        "Use the `concat` function to do this. The function should return a DataFrame with 25 columns (first five related to the date and then the rest 20 conserning the measument location.\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmspGECstlqK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cGQJCsoHeTB"
      },
      "source": [
        "## Merging dataframes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IJ6W42HHeTD"
      },
      "source": [
        "Merging combines two DataFrames based on some common field."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v38TAakHeTD"
      },
      "source": [
        "Let's recall the earlier DataFrame about wages and ages of persons:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPipjHd_HeTH"
      },
      "source": [
        "df = pd.DataFrame([[1000, \"Jack\", 21], [1500, \"John\", 29]], columns=[\"Wage\", \"Name\", \"Age\"])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjv3AnfvHeTK"
      },
      "source": [
        "Now, create a new DataFrame with the occupations of persons:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJgkLSeCHeTL"
      },
      "source": [
        "df2 = pd.DataFrame({\"Name\" : [\"John\", \"Jack\"], \"Occupation\": [\"Plumber\", \"Carpenter\"]})\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7F2AX_fHeTP"
      },
      "source": [
        "The following function call will merge the two DataFrames on their common field, and, importantly, will keep the indices *aligned*. What this means is that even though the names are listed in different order in the two frames, the merge will still give correct result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EExjxclyHeTR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaarefbNHeTT"
      },
      "source": [
        "This was an example of a simple one-to-one merge, where the keys in the `Name` columns had 1-to-1 correspondence. Sometimes not all the keys appear in both DataFrames:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3dvLta2HeTU"
      },
      "source": [
        "df3 = pd.concat([df2, pd.DataFrame({ \"Name\" : [\"James\"], \"Occupation\":[\"Painter\"]})], ignore_index=True)\n",
        "df3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2i0TTetHeTY"
      },
      "source": [
        "print(df)\n",
        "pd.merge(df, df3)  # By default an inner join is computed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjnUk7wOHeTc"
      },
      "source": [
        "pd.merge(df, df3, how=\"outer\")   # Outer join"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp7tVUwUHeTl"
      },
      "source": [
        "Also, many-to-one and many-to-many relationships can occur in merges:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21fE5HzpHeTo"
      },
      "source": [
        "books = pd.DataFrame({\"Title\" : [\"War and Peace\", \"Good Omens\", \"Good Omens\"] , \n",
        "                      \"Author\" : [\"Tolstoi\", \"Terry Pratchett\", \"Neil Gaiman\"]})\n",
        "books"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhZgBjCAHeTu"
      },
      "source": [
        "collections = pd.DataFrame([[\"Oodi\", \"War and Peace\"],\n",
        "                           [\"Oodi\", \"Good Omens\"],\n",
        "                           [\"Pasila\", \"Good Omens\"],\n",
        "                           [\"Kallio\", \"War and Peace\"]], columns=[\"Library\", \"Title\"])\n",
        "collections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNYHegUtHeT0"
      },
      "source": [
        "All combinations with matching keys (`Title`) are created:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWnphVhtHeT5"
      },
      "source": [
        "libraries_with_books_by = pd.merge(books, collections)\n",
        "libraries_with_books_by"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky9ZNCQWHeT_"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 20 (cycling weather)</div>\n",
        "\n",
        "Merge the processed cycling data set (from the previous exercise) and weather data set along the columns year, month, and day. Note that the names of these columns might be different in the two tables: use the `left_on` and `right_on` parameters. Then drop useless columns 'm', 'd', 'Time', and 'Time zone'.\n",
        "\n",
        "Write function `cycling_weather` that reads the data sets and returns the resulting DataFrame.\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoPnyeRsuhsw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuDP5Z9THeUC"
      },
      "source": [
        "## Aggregates and groupings\n",
        "\n",
        "Let us use again the weather dataset. First, we make the column names a bit more uniform and concise. For example the columns `Year`, `m`, and `d` are not uniformly named.\n",
        "\n",
        "We can easily change the column names with the `rename` method of the DataFrame. Note that we cannot directly change the index `wh.index` as it is immutable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC-Ncdh5HeUC"
      },
      "source": [
        "wh = pd.read_csv(\"https://raw.githubusercontent.com/smabb/p/master/data/temp.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcM2poefHeUF"
      },
      "source": [
        "wh3 = wh.rename(columns={\"m\": \"Month\", \"d\": \"Day\", \"Precipitation amount (mm)\" : \"Precipitation\", \n",
        "                         \"Snow depth (cm)\" : \"Snow\", \"Air temperature (degC)\" : \"Temperature\"})\n",
        "wh3.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TSKEbYmHeUM"
      },
      "source": [
        "Pandas has an operation that splits a DataFrame into groups, performs some operation on each of the groups, and then combines the result from each group into a resulting DataFrame. This split-apply-combine functionality is really flexible and powerful operation. In Pandas you start by calling the `groupby` method, which splits the DataFrame into groups. In the following example the rows that contain measurements from the same month belong to the same group:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q4G9vaMHeUN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmkAfJwlHeUT"
      },
      "source": [
        "Nothing happened yet, but the `groupby` object knows how the division into groups is done. This is called a lazy operation. We can query the number of groups in the `groupby` object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyNRReiIHeUV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-9f3JoVHeUZ"
      },
      "source": [
        "We can iterate through all the groups:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YskEZqi6HeUa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu-Eo9m4HeUd"
      },
      "source": [
        "              # Group with index two "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXi1ZfyrHeUf"
      },
      "source": [
        "The `groupby` object functions a bit like a DataFrame, so some operations which are allowed for DataFrames are also allowed for the `groupby` object. For example, we can get a subset of columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9u3mXjAHeUf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uUgR8E3HeUk"
      },
      "source": [
        "For each DataFrame corresponding to a group the Temperature column was chosen. Still nothing was shown, because we haven't applied any operation on the groups."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRERi3QQHeUk"
      },
      "source": [
        "The common methods also include the aggregation methods. Let's try to apply the `mean` aggregation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz8E5C7KHeUl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whQrlQjayBB1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN4gBQ3Pxr0e"
      },
      "source": [
        "Now what happened was that after the mean aggregation was performed on each group, the results were automatically combined into a resulting DataFrame. Let's try some other aggregation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIxilHT29hXt"
      },
      "source": [
        "### Other ways to operate on groups\n",
        "\n",
        "The aggregations are not the only possible operations on groups. The other possibilities are filtering, transformation, and application.\n",
        "\n",
        "In **filtering** some of the groups can be filtered out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgvk5atuHeU8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWQVHM5DHeVF"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 21 (cyclists per day)</div>\n",
        "\n",
        "\n",
        "\n",
        "Part 1.\n",
        "\n",
        "Read, clean and parse the bicycle data set as before. Group the rows by year, month, and day. Get the sum for each group.\n",
        "Make function `cyclists_per_day` that does the above. The function should return a DataFrame.\n",
        "Make sure that the columns Hour and Weekday are not included in the returned DataFrame.\n",
        "\n",
        "Part 2.\n",
        "\n",
        "Using the function `cyclists_per_day`, get the daily counts.  The index of the DataFrame now consists of tuples (Year, Month, Day). Then restrict this data to August of year 2017, and plot this data. Don't forget to call the `plt.show` function of matplotlib. The x-axis should have ticks from 1 to 31, and there should be a curve to each measuring station. Can you spot the weekends?\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9Zk7doY0QMM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMUvH1jaHeVF"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 22 (best Performer)</div>\n",
        "\n",
        "We use again the top100 data set from the first week of 1964 i. Here we define \"goodness\" of the Performer  based on the sum of the weeks on chart of its singles. Return a DataFrame of the singles by the best Performer (a subset of rows of the original DataFrame). Do this with function `best_Performer`.\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZgt9-I_-CcS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfUfefoqHeVN"
      },
      "source": [
        "## Time series\n",
        "\n",
        "If a measurement is made at certain points in time, the resulting values with their measurement times is called a time series. In Pandas a Series whose index consists of dates/times is a time series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT2fS1WdHeVO"
      },
      "source": [
        "Let's make a copy of the DataFrame that we can mess with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6MXexAQHeVO"
      },
      "source": [
        "wh2 = wh3.copy()\n",
        "wh2.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPqERlOAHeVT"
      },
      "source": [
        "The column names `Year`, `Month`, and `Day` are now in appropriate form for the `to_datetime` function. It can convert these fields into a timestamp series, which we will add to the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NSAYEl_HeVU"
      },
      "source": [
        "wh2[\"Date\"] = pd.to_datetime(wh2[[\"Year\", \"Month\", \"Day\"]])\n",
        "wh2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7yrFn2VHeVf"
      },
      "source": [
        "We can now drop the useless fields:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aeA1_7zHeVh"
      },
      "source": [
        "wh2=wh2.drop(columns=[\"Year\", \"Month\", \"Day\"])\n",
        "wh2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUgHRxdFHeVl"
      },
      "source": [
        "The following method call will set the Date field as the index of the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4K9Mu4FHeVm"
      },
      "source": [
        "wh2 = wh2.set_index(\"Date\")\n",
        "wh2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFFPda1yHeVp"
      },
      "source": [
        "We can now easily get a set of rows using date slices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNbHZ08dHeVq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMouUg33HeVs"
      },
      "source": [
        "By using the `date_range` function even more complicated sets can be formed. The following gets all the Mondays of Jan:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_asnLFaHeVs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZZkpwf22hrq"
      },
      "source": [
        "More freq offsets https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_ZnyjqiHeVu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O97rm4j7HeVv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52esFgPQHeVy"
      },
      "source": [
        "The following finds all the business days (Monday to Friday) of July:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEGo4w-NHeVy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdC1ANNAHeV1"
      },
      "source": [
        "We can get a general idea about the `Temperature` column by plotting it. Note how the index time series is shown nicely on the x-axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hf7fUDIHeV2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bxLR_E8HeV9"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 23 (bicycle timeseries)</div>\n",
        "\n",
        "Write function `bicycle_timeseries` that\n",
        "\n",
        "* reads the data set\n",
        "* cleans it\n",
        "* turns its `Date` column into (row) DatetimeIndex (that is, to row names) of that DataFrame\n",
        "* returns the new DataFrame\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPqNCyLq4dds"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpdrFiVnHeV-"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 24 (commute)</div>\n",
        "\n",
        "In function `commute` do the following:\n",
        "\n",
        "Use the function `bicycle_timeseries` to get the bicycle data. Restrict to November 2017, group by the weekday, aggregate by summing. Set the `Weekday` column to numbers from one to seven. Then set the column `Weekday` as the (row) index. Return the resulting DataFrame from the function.\n",
        "\n",
        " plot the DataFrame. Xticklabels should be the weekdays. \n",
        "\n",
        "\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmIPwcld-oTa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ly5K57ZHT7A"
      },
      "source": [
        "## Summary \n",
        "* Operations maintain these indices even when adding or removing rows or columns\n",
        "* Indices also allow several operations to be combined meaningfully and easily\n",
        "* You can create DataFrames in several ways:\n",
        "     * By reading from a csv file\n",
        "     * Out out two dimensional NumPy array\n",
        "     * Out of rows\n",
        "     * Out of columns\n",
        "* You know how to access rows, columns and individual elements of DataFrames\n",
        "* You can use the `describe` method to get a quick overview of a DataFrame\n",
        "* You know how missing values are represented in Series and DataFrames, and you know how to manipulate them\n",
        "* There are similarities between Python's string methods and the vectorized forms of string operations in Series and DataFrames\n",
        "* We remember that with NumPy arrays we preferred vectorized operations instead of, for instance, `for` loops. Same goes with Pandas. It may first feel that things are easier to achieve with loops, but after a while vectorized operations will feel natural."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSLyA8HsHeV-"
      },
      "source": [
        "## Additional information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5Swg-L9HeV_"
      },
      "source": [
        "[Pandas cheat sheet](https://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf) Summary of most important Pandas' functions and methods.\n",
        "\n",
        "\n",
        "\n",
        "Pandas handles only one dimensional data (Series) and two dimensional data (DataFrame). While you can use [hierarchical indices](http://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html#hierarchical-indexing-multiindex) to simulate higher dimensional arrays, you should use the [xarray](http://xarray.pydata.org/en/stable/index.html) library, if you need proper higher-dimensional arrays with labels. It is basically a cross between NumPy and Pandas.\n",
        "\n"
      ]
    }
  ]
}